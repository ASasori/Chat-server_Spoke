# spoke_executor.py

import requests
from requests.models import Request
import json
import re
from urllib.parse import urlparse, parse_qs
from typing import Dict, Any, List, Optional
from modules.llm_client import BaseLLMClient # For type hinting

class SpokeExecutor:
    """
    Executes a JSON plan generated by SmartSearch by calling the
    SPOKE API, pruning results (optionally), and performing logic.
    """
    
    def __init__(
        self,
        base_url: str = "https://spoke.rbvi.ucsf.edu",
        pruning_threshold: int = 15,
        llm_client: Optional[BaseLLMClient] = None
    ):
        """
        Initializes the Executor.

        Args:
            base_url: The base URL for the SPOKE API.
            pruning_threshold: Max nodes before triggering LLM pruning.
            llm_client: An *optional* LLM client. If provided,
                        LLM-in-the-loop pruning will be enabled.
        """
        self.base_url = base_url
        self.session = requests.Session()
        self.final_result_limit = 15
        self.llm_client = llm_client
        self.pruning_threshold = pruning_threshold
        
        pruning_status = "DISABLED"
        if self.llm_client:
            pruning_status = f"ENABLED (threshold: {self.pruning_threshold})"
            
        print(f"âœ“ SpokeExecutor initialized. LLM Pruning: {pruning_status}")

    
    async def execute_plan(self, plan_json: Dict[str, Any], original_nlq: str) -> Dict[str, Any]:
        """
        Main entry point. Executes a full plan and returns the final
        context store (dictionary).
        """
        print(f"\n--- [Executor] Executing {plan_json.get('query_type')} plan... ---")
        results_store = {}
        
        plan_steps = plan_json.get("plan", [])
        
        for i, step in enumerate(plan_steps):
            print(f"  [Step {step['step']}] {step['description']}")
            
            step_result = None
            
            if step.get("api_call"):
                step_result = await self._execute_api_step(step, results_store)
            
            elif step.get("logic"):
                step_result = await self._execute_logic_step(step, results_store)

            
            # --- *** LLM-IN-THE-LOOP PRUNING LOGIC *** ---
            
            # 1. Check if the result is a large list
            if (isinstance(step_result, list) and 
                len(step_result) > self.pruning_threshold):
                
                # 2. Check if this is an intermediate step
                is_intermediate = False
                next_step_description = "process the data" # Default
                
                if (i + 1) < len(plan_steps): # If not the last step
                    for future_step in plan_steps[i+1:]:
                        if step["store_as"] in future_step.get("inputs", []):
                            is_intermediate = True
                            next_step_description = future_step.get("description", next_step_description)
                            break
                
                # 3. Call LLM to prune *only if* it's intermediate AND LLM client was provided
                if is_intermediate and self.llm_client:
                    print(f"    ! Pruning '{step['store_as']}': list is large ({len(step_result)} nodes).")
                    step_result = await self._prune_node_list(
                        original_nlq,
                        step_result,
                        next_step_description
                    )
                elif is_intermediate:
                     print(f"    ! Skipping pruning for '{step['store_as']}' (LLM client not provided).")

            # --- *** END OF PRUNING LOGIC *** ---

            # Store the (potentially pruned) result
            if step_result is not None:
                results_store[step["store_as"]] = step_result
                if isinstance(step_result, list):
                    print(f"    -> Stored {len(step_result)} nodes in '{step['store_as']}'")
                else:
                    print(f"    -> Stored result in '{step['store_as']}'")
            else:
                print(f"    ! Warning: Step {step['step']} produced no result.")
                results_store[step["store_as"]] = []
        
        print("--- [Executor] Plan finished. ---")
        
        # --- NEW: Return the *entire* store ---
        # The Answer Generator needs all intermediate steps for reasoning.
        
        # Truncate final_result *within* the store for clarity in the final answer
        final_results = results_store.get("final_result", [])
        if isinstance(final_results, list) and len(final_results) > self.final_result_limit:
            print(f"--- [Final Result] Found {len(final_results)} items. Truncating to {self.final_result_limit}. ---")
            results_store["final_result"] = final_results[:self.final_result_limit]
        else:
            print(f"--- [Final Result] Found {len(final_results)} items. ---")

        return results_store


    async def _prune_node_list(self, nlq: str, node_list: List[Dict], next_step_desc: str) -> List[Dict]:
        """
        Uses the LLM to prune a large node list based on the original question.
        """
        print(f"    -> [PRUNING] Calling LLM to prune {len(node_list)} nodes for step: '{next_step_desc}'")
        
        # 1. Extract names from the node list
        node_names = []
        for node in node_list:
            try:
                name = node['data']['properties']['name']
                node_names.append(name)
            except (KeyError, TypeError):
                continue
        
        unique_names = sorted(list(set(node_names)))
        if not unique_names:
            print("    ! [PRUNING] No names found to prune. Returning original list.")
            return node_list

        # 2. Build the Pruning Prompt
        pruning_prompt = f"""
        You are an expert biomedical reasoning agent. Your task is to prune a large list of nodes to make a graph query more efficient.

        The user's original question is:
        "{nlq}"

        I have just found {len(unique_names)} potential nodes. My *next* step in the plan is to:
        "{next_step_desc}"

        This list is too large to process. Please select the **Top {self.pruning_threshold}** most relevant, common, or severe nodes from the following list that I should investigate further for my *next* step.

        Full list of {len(unique_names)} node names:
        {json.dumps(unique_names)}

        You MUST respond with a JSON object containing a *single key* "selected_names", which is a list of the exact string names you selected.
        Example: {{"selected_names": ["Name 1", "Name 2", "Name 3"]}}
        """

        try:
            # 3. Call LLM (using the client with retry logic)
            # This check is technically redundant if execute_plan is correct,
            # but it's good practice.
            if not self.llm_client:
                return node_list
                
            raw_json_string = await self.llm_client.generate(pruning_prompt)
            print(f"    -> [PRUNING] LLM raw response: {raw_json_string[:100]}...")
            
            parsed_response = json.loads(raw_json_string)
            selected_names = parsed_response.get("selected_names")
            
            if not selected_names or not isinstance(selected_names, list):
                print(f"    ! [PRUNING] LLM response invalid. Returning original list.")
                return node_list

            # 4. Filter the *original* node list
            selected_name_set = set(selected_names)
            pruned_list = []
            
            for node in node_list:
                try:
                    name = node['data']['properties']['name']
                    if name in selected_name_set:
                        pruned_list.append(node)
                except (KeyError, TypeError):
                    continue
            
            # 5. Deduplicate the resulting list of nodes
            unique_nodes = {}
            for node in pruned_list:
                try:
                    identifier = node['data']['properties']['identifier']
                    if identifier not in unique_nodes:
                        unique_nodes[identifier] = node
                except (KeyError, TypeError):
                    continue 

            final_pruned_list = list(unique_nodes.values())
            
            print(f"    -> [PRUNING] Successful. List reduced from {len(node_list)} to {len(final_pruned_list)} nodes.")
            return final_pruned_list

        except Exception as e:
            print(f"    ! [PRUNING] Error during LLM pruning call: {e}. Returning original list.")
            return node_list

    
    async def _execute_api_step(self, step: Dict[str, Any], store: Dict[str, Any]) -> Any:
        """Handles any 'api_call' step."""
        api_call_str = step["api_call"]
        inputs = step.get("inputs")
        
        if not inputs:
            # This is an "anchor" call that starts a query
            return await self._execute_simple_neighborhood_call(api_call_str)
        
        # This is a "looping" call that uses previous results
        input_var_name = inputs[0]
        input_data = store.get(input_var_name)

        if not input_data or not isinstance(input_data, list):
            print(f"    ! Error: Input '{input_var_name}' not found or is not a list.")
            return None
        
        return await self._execute_looping_neighborhood_call(step, input_data)

    async def _execute_simple_neighborhood_call(self, api_call: str) -> List[Dict[str, Any]]:
        """Executes a single, non-looping API call."""
        try:
            url = f"{self.base_url}{api_call}"
            print(f"    -> Calling [NEIGHBORHOOD-ANCHOR]: GET {url}")
            response = self.session.get(url)
            response.raise_for_status()
            results = response.json()
            
            if not results:
                print(f"    ! Warning: Anchor query returned no results.")
                return []

            # Filter for *neighbor nodes* only (not the anchor itself)
            neighbor_nodes = []
            for item in results:
                data = item.get("data")
                if not data:
                    continue
                
                # neo4j_root == 0 means it's a neighbor, not the root
                if data.get("neo4j_root") == 0 and "source" not in data:
                    if data.get("neo4j_type") and data.get("properties", {}).get("name"):
                        neighbor_nodes.append(item)
            
            if not neighbor_nodes:
                print(f"    ! Warning: Anchor query found results, but no valid neighbor nodes.")

            return neighbor_nodes
            
        except requests.exceptions.RequestException as e:
            print(f"    ! API Error (Anchor Neighborhood): {e}")
            return []

    async def _execute_looping_neighborhood_call(self, step: Dict[str, Any], input_nodes: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Executes API calls by looping over a list of input nodes."""
        if not input_nodes:
            print("    -> Skipping loop: input list is empty.")
            return []
            
        api_call_template = step["api_call"]
        parsed_url = urlparse(api_call_template)
        query_params = parse_qs(parsed_url.query) 

        all_neighbor_nodes = []
        print(f"    -> Calling [NEIGHBORHOOD-LOOP]: Executing {len(input_nodes)} calls...")
        
        for node in input_nodes:
            try:
                node_data = node["data"]
                node_properties = node_data["properties"]
                node_type = node_data.get("neo4j_type")
                node_name = node_properties.get("name")
                if not node_type or not node_name:
                    print(f"    ! Skipping node: missing 'neo4j_type' or 'name'.")
                    continue
            except (KeyError, TypeError) as e:
                print(f"    ! Skipping node: invalid structure. {e}")
                continue
            
            # Construct the API path for *this* node
            base_path = f"/api/v1/neighborhood/{node_type}/name/{node_name}"
            url = f"{self.base_url}{base_path}"
            
            temp_request = Request('GET', url, params=query_params).prepare()
            print(f"    -> API Call: {temp_request.url}")

            try:
                response = self.session.get(url, params=query_params)
                response.raise_for_status()
                neighbors = response.json()
                
                # Filter for neighbor nodes
                filtered_neighbors = []
                for item in neighbors:
                    data = item.get("data")
                    if not data:
                        continue
                        
                    if data.get("neo4j_root") == 0 and "source" not in data:
                         if data.get("neo4j_type") and data.get("properties", {}).get("name"):
                            filtered_neighbors.append(item)
                all_neighbor_nodes.extend(filtered_neighbors)

            except requests.exceptions.RequestException as e:
                print(f"    ! API Error (Loop): {e} on {url}")

        print(f"    -> [LOOP] Completed, found {len(all_neighbor_nodes)} total neighbors (pre-deduplication).")

        # Deduplicate the final list based on node identifier
        unique_nodes = {}
        for node in all_neighbor_nodes:
            try:
                identifier = node['data']['properties']['identifier']
                if identifier not in unique_nodes:
                    unique_nodes[identifier] = node
            except (KeyError, TypeError):
                print(f"    ! Warning: Could not find identifier for node. {node}")
        
        return list(unique_nodes.values())

    async def _get_nodes_by_identifier(self, node_list: List[Dict[str, Any]]) -> Dict[str, Dict[str, Any]]:
        """Helper to create a dictionary of nodes keyed by their identifier."""
        nodes_by_id = {}
        for node in node_list:
            try:
                identifier = node['data']['properties']['identifier']
                nodes_by_id[identifier] = node
            except (KeyError, TypeError):
                print(f"    ! Warning (Logic): Could not find identifier for node. {node}")
        return nodes_by_id

    async def _execute_logic_step(self, step: Dict[str, Any], store: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Handles 'logic' steps like UNION and INTERSECTION."""
        logic_op = step["logic"]
        input_a_name, input_b_name = step["inputs"]
        list_A = store.get(input_a_name, [])
        list_B = store.get(input_b_name, [])

        # Use identifiers for robust set operations
        nodes_A_by_id = await self._get_nodes_by_identifier(list_A)
        nodes_B_by_id = await self._get_nodes_by_identifier(list_B)

        if logic_op == "UNION":
            print(f"    -> Logic: Performing UNION on {len(nodes_A_by_id)} and {len(nodes_B_by_id)} nodes.")
            nodes_A_by_id.update(nodes_B_by_id) # Merge B into A
            return list(nodes_A_by_id.values())
        
        elif logic_op == "INTERSECTION":
            print(f"    -> Logic: Performing INTERSECTION on {len(nodes_A_by_id)} and {len(nodes_B_by_id)} nodes.")
            ids_A = nodes_A_by_id.keys()
            ids_B = nodes_B_by_id.keys()
            common_ids = ids_A & ids_B # Set intersection
            return [nodes_A_by_id[node_id] for node_id in common_ids]
        
        else:
            print(f"    ! Unknown logic op: {logic_op}")
            return []