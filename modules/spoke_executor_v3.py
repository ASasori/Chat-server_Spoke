import requests
from requests.models import Request
import json
from urllib.parse import urlparse, parse_qs, unquote
from typing import Dict, Any, List, Optional
from modules.llm_client import BaseLLMClient

class SpokeExecutor3:
    """
    Executes a JSON plan generated by SmartSearch by calling the
    SPOKE API, pruning results, and strictly managing token usage.
    """
    
    def __init__(
        self,
        base_url: str = "https://spoke.rbvi.ucsf.edu",
        pruning_threshold: int = 20, # Tăng nhẹ mặc định lên 20
        llm_client: Optional[BaseLLMClient] = None
    ):
        self.base_url = base_url
        self.session = requests.Session()
        self.final_result_limit = 20 # Tăng limit cuối cùng
        self.llm_client = llm_client
        self.pruning_threshold = pruning_threshold
        
        pruning_status = "DISABLED"
        if self.llm_client:
            pruning_status = f"ENABLED (threshold: {self.pruning_threshold})"
            
        print(f"✓ SpokeExecutor initialized. LLM Pruning: {pruning_status}")

    def _extract_node_info(self, raw_api_node: Dict, prev_node_name: Optional[str] = None) -> Optional[Dict[str, Any]]:
        """
        Helper: Flattens the heavy SPOKE API response into a lightweight dict 
        to save tokens.
        
        Structure:
        {
            "name": "...",
            "type": "...",
            "prev_node": "...",
            "identifier": ... (kept for deduplication logic only)
        }
        """
        try:
            data = raw_api_node.get("data", {})
            props = data.get("properties", {})
            
            # Essential fields only
            name = props.get("name")
            neo4j_type = data.get("neo4j_type")
            identifier = props.get("identifier")

            if not name or not neo4j_type:
                return None

            return {
                "name": name,
                "type": neo4j_type,
                "prev_node": prev_node_name, 
                "identifier": identifier 
            }
        except Exception:
            return None

    async def execute_plan(self, plan_json: Dict[str, Any], original_nlq: str) -> Dict[str, Any]:
        """
        Main entry point. Executes plan and returns results_store containing 
        ONLY lightweight node objects.
        """
        print(f"\n--- [Executor] Executing {plan_json.get('query_type')} plan... ---")
        results_store = {}
        
        plan_steps = plan_json.get("plan", [])
        
        for i, step in enumerate(plan_steps):
            print(f"  [Step {step['step']}] {step['description']}")
            
            step_result = None
            
            if step.get("api_call"):
                step_result = await self._execute_api_step(step, results_store)
            
            elif step.get("logic"):
                step_result = await self._execute_logic_step(step, results_store)

            
            # --- *** LLM-IN-THE-LOOP PRUNING LOGIC *** ---
            if (isinstance(step_result, list) and 
                len(step_result) > self.pruning_threshold):
                
                is_intermediate = False
                next_step_description = "process the data"
                
                if (i + 1) < len(plan_steps): 
                    for future_step in plan_steps[i+1:]:
                        future_inputs = future_step.get("inputs") or []
                        if step["store_as"] in future_inputs:
                            is_intermediate = True
                            next_step_description = future_step.get("description", next_step_description)
                            break
                
                if is_intermediate and self.llm_client:
                    print(f"    ! Pruning '{step['store_as']}': list is large ({len(step_result)} nodes).")
                    step_result = await self._prune_node_list(
                        original_nlq,
                        step_result,
                        next_step_description
                    )
                elif is_intermediate:
                     print(f"    ! Skipping pruning for '{step['store_as']}' (LLM client not provided).")

            # --- *** END OF PRUNING LOGIC *** ---

            # Store the result
            if step_result is not None:
                results_store[step["store_as"]] = step_result
                if isinstance(step_result, list):
                    print(f"    -> Stored {len(step_result)} lightweight nodes in '{step['store_as']}'")
                else:
                    print(f"    -> Stored result in '{step['store_as']}'")
            else:
                print(f"    ! Warning: Step {step['step']} produced no result.")
                results_store[step["store_as"]] = []
        
        print("--- [Executor] Plan finished. ---")
        
        # Truncate final result if necessary
        final_results = results_store.get("final_result", [])
        if isinstance(final_results, list) and len(final_results) > self.final_result_limit:
            print(f"--- [Final Result] Found {len(final_results)} items. Truncating to {self.final_result_limit}. ---")
            results_store["final_result"] = final_results[:self.final_result_limit]
        else:
            print(f"--- [Final Result] Found {len(final_results)} items. ---")

        return results_store

    async def _prune_node_list(self, nlq: str, node_list: List[Dict], next_step_desc: str) -> List[Dict]:
        """
        Uses the LLM to prune list, BUT keeps context of 'prev_node' to ensure diversity.
        """
        # 1. Dynamic Threshold Calculation
        # Nếu danh sách quá lớn, threshold nên nới lỏng ra một chút để tránh mất tin
        current_threshold = self.pruning_threshold
        if len(node_list) > 50:
            current_threshold = int(self.pruning_threshold * 1.5) # Tăng 50% nếu input quá nhiều

        print(f"    -> [PRUNING] Calling LLM to prune {len(node_list)} nodes. Target: Top {current_threshold}. Step: '{next_step_desc}'")
        
        # 2. Group nodes by prev_node for the Prompt
        # Format gửi cho LLM: "Disease A -> Symptom X", "Disease B -> Symptom Y"
        node_display_list = []
        for node in node_list:
            name = node.get('name')
            prev = node.get('prev_node', 'Unknown')
            # Tạo chuỗi đại diện: "Cha: Con" để LLM hiểu ngữ cảnh
            display_str = f"{prev} -> {name}"
            node_display_list.append(display_str)
        
        # Deduplicate strings for prompt
        unique_display_list = sorted(list(set(node_display_list)))

        if not unique_display_list:
            return node_list

        candidate_list = json.dumps(unique_display_list)

        # 3. Build the Context-Aware Pruning Prompt
        pruning_prompt = f"""
        You are a smart biomedical data filter.
        User Query: "{nlq}"
        Next Process Step: "{next_step_desc}"

        I have a list of {len(unique_display_list)} items in format "Parent_Node -> Item_Name".
        
        **CRITICAL INSTRUCTION:**
        Select the **Top {current_threshold}** most relevant items.
        You MUST maintain **DIVERSITY**. If the list contains items from multiple different "Parent_Nodes", you MUST try to keep at least 1-2 items for EACH Parent_Node. Do not let one Parent_Node dominate the list.

        Candidate List:
        {candidate_list}

        Respond ONLY with a JSON object containing a list of the exact strings you selected:
        {{"selected_items": ["Parent A -> Item 1", "Parent B -> Item 2"]}}
        """

        try:
            if not self.llm_client:
                return node_list
                
            raw_json_string = await self.llm_client.filter_nodes(pruning_prompt)
            # Clean json string if needed (sometimes LLM adds markdown ```json ... ```)
            if "```json" in raw_json_string:
                raw_json_string = raw_json_string.split("```json")[1].split("```")[0].strip()
            elif "```" in raw_json_string:
                raw_json_string = raw_json_string.split("```")[1].split("```")[0].strip()

            parsed_response = json.loads(raw_json_string)
            selected_items = parsed_response.get("selected_items")
            
            if not selected_items or not isinstance(selected_items, list):
                print("    ! [PRUNING] Invalid response format. Keeping original.")
                return node_list

            # 4. Map back to original nodes
            # selected_items là danh sách các chuỗi "Prev -> Name"
            selected_set = set(selected_items)
            pruned_list = []
            unique_ids = set()

            for node in node_list:
                name = node.get('name')
                prev = node.get('prev_node', 'Unknown')
                display_key = f"{prev} -> {name}"
                
                # Check 1: Is explicitly selected?
                # Check 2: Fallback - if LLM returned just "Name" (hallucination check), match name
                is_selected = (display_key in selected_set)
                
                if is_selected:
                    # Deduplication
                    identifier = node.get('identifier', f"{node['type']}:{name}")
                    if identifier not in unique_ids:
                        unique_ids.add(identifier)
                        pruned_list.append(node)
            
            # Fallback an toàn: Nếu LLM filter quá tay (trả về rỗng hoặc quá ít < 3), giữ lại list gốc
            if len(pruned_list) < 3 and len(node_list) > 3:
                 print("    ! [PRUNING] LLM pruned too aggressively. Using logic fallback (Taking top items per parent).")
                 return node_list[:current_threshold] # Hoặc logic fallback thông minh hơn

            print(f"    -> [PRUNING] Successful. Reduced {len(node_list)} -> {len(pruned_list)} nodes (Context-Aware).")
            return pruned_list

        except Exception as e:
            print(f"    ! [PRUNING] Error: {e}. Returning original list.")
            return node_list
    
    async def _execute_api_step(self, step: Dict[str, Any], store: Dict[str, Any]) -> Any:
        api_call_str = step["api_call"]
        inputs = step.get("inputs")
        
        if not inputs:
            # Anchor call (First step)
            return await self._execute_simple_neighborhood_call(api_call_str)
        
        # Looping call
        input_var_name = inputs[0]
        input_data = store.get(input_var_name)

        if not input_data or not isinstance(input_data, list):
            print(f"    ! Error: Input '{input_var_name}' not found or is not a list.")
            return []
        
        return await self._execute_looping_neighborhood_call(step, input_data)

    async def _execute_simple_neighborhood_call(self, api_call: str) -> List[Dict[str, Any]]:
        """Executes a single, non-looping API call and returns simplified nodes."""
        try:
            url = f"{self.base_url}{api_call}"
            print(f"    -> Calling [NEIGHBORHOOD-ANCHOR]: GET {url}")
            response = self.session.get(url)
            response.raise_for_status()
            results = response.json()
            
            if not results:
                return []

            simplified_neighbors = []
            
            # --- IMPROVED ANCHOR NAME EXTRACTION ---
            # 1. Parse URL to separate path from query params (removes ?edge_filters=...)
            parsed_url = urlparse(url)
            path_segments = parsed_url.path.strip('/').split('/')
            
            # 2. Find the segment after 'name', e.g., .../name/Metformin
            anchor_name = "Original Query" # Default fallback
            if "name" in path_segments:
                try:
                    # Find index of 'name' and get the next element
                    name_index = path_segments.index("name")
                    if name_index + 1 < len(path_segments):
                        # 3. Decode the URL (e.g., 'Lung%20Cancer' -> 'Lung Cancer')
                        anchor_name = unquote(path_segments[name_index + 1])
                except ValueError:
                    pass
            elif path_segments:
                 # Fallback: take the last segment if 'name' keyword isn't found
                 anchor_name = unquote(path_segments[-1])

            for item in results:
                # Check raw item for neighbor status
                data = item.get("data", {})
                if data.get("neo4j_root") == 0 and "source" not in data:
                    # Convert to LIGHTWEIGHT format
                    # CLEANER: passing anchor_name directly without "Query: " prefix
                    simple_node = self._extract_node_info(item, prev_node_name=anchor_name)
                    if simple_node:
                        simplified_neighbors.append(simple_node)
            
            return simplified_neighbors
            
        except requests.exceptions.RequestException as e:
            print(f"    ! API Error (Anchor): {e}")
            return []

    async def _execute_looping_neighborhood_call(self, step: Dict[str, Any], input_nodes: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        Executes API calls looping over lightweight input nodes.
        Passes current node name as 'prev_node' to children.
        """
        if not input_nodes:
            return []
            
        api_call_template = step["api_call"]
        parsed_url = urlparse(api_call_template)
        query_params = parse_qs(parsed_url.query) 

        all_neighbor_nodes = []
        print(f"    -> Calling [NEIGHBORHOOD-LOOP]: Executing {len(input_nodes)} calls...")
        
        for prev_node in input_nodes:
            # lightweight nodes have keys: 'name', 'type', 'prev_node'
            node_name = prev_node.get("name")
            node_type = prev_node.get("type")
            
            if not node_name or not node_type:
                continue
            
            # Construct API path
            base_path = f"/api/v1/neighborhood/{node_type}/name/{node_name}"
            url = f"{self.base_url}{base_path}"
            
            try:
                response = self.session.get(url, params=query_params)
                response.raise_for_status()
                neighbors = response.json()
                
                for item in neighbors:
                    data = item.get("data", {})
                    # Ensure it's a neighbor (neo4j_root == 0)
                    if data.get("neo4j_root") == 0 and "source" not in data:
                        # *** CRITICAL: Set prev_node to the parent's name ***
                        simple_node = self._extract_node_info(item, prev_node_name=node_name)
                        if simple_node:
                            all_neighbor_nodes.append(simple_node)

            except requests.exceptions.RequestException:
                # Silently fail on individual node errors to keep loop moving
                continue

        print(f"    -> [LOOP] Completed, found {len(all_neighbor_nodes)} neighbors.")

        # Deduplicate using identifier
        unique_nodes = {}
        for node in all_neighbor_nodes:
            # If identifier is missing, fallback to name-type combo, or just name
            identifier = node.get("identifier", f"{node['type']}:{node['name']}")
            if identifier not in unique_nodes:
                unique_nodes[identifier] = node
        
        return list(unique_nodes.values())

    async def _get_nodes_by_identifier(self, node_list: List[Dict[str, Any]]) -> Dict[Any, Dict[str, Any]]:
        """Helper for logic operations using flattened structure."""
        nodes_by_id = {}
        for node in node_list:
            identifier = node.get("identifier")
            if identifier is not None:
                nodes_by_id[identifier] = node
        return nodes_by_id

    async def _execute_logic_step(self, step: Dict[str, Any], store: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Handles UNION and INTERSECTION on lightweight nodes."""
        logic_op = step["logic"]
        input_a_name, input_b_name = step["inputs"]
        list_A = store.get(input_a_name, [])
        list_B = store.get(input_b_name, [])

        nodes_A_by_id = await self._get_nodes_by_identifier(list_A)
        nodes_B_by_id = await self._get_nodes_by_identifier(list_B)

        if logic_op == "UNION":
            print(f"    -> Logic: UNION {len(nodes_A_by_id)} | {len(nodes_B_by_id)}")
            nodes_A_by_id.update(nodes_B_by_id)
            return list(nodes_A_by_id.values())
        
        elif logic_op == "INTERSECTION":
            print(f"    -> Logic: INTERSECTION {len(nodes_A_by_id)} & {len(nodes_B_by_id)}")
            ids_A = set(nodes_A_by_id.keys())
            ids_B = set(nodes_B_by_id.keys())
            common_ids = ids_A & ids_B
            return [nodes_A_by_id[node_id] for node_id in common_ids]
        
        return []